{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "interpreter": {
      "hash": "f4a381d9d3db2133197d2af93d93a0bc1bd0660cb0ffeb3da2d515607f4a9fcc"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "XGBoost1_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4840219"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import e\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns # for correlation heatmap\n",
        "data = load_breast_cancer(as_frame=True)\n",
        "x=data.data"
      ],
      "id": "f4840219",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2a49c16"
      },
      "source": [
        "class Node:\n",
        "    split_imp=dict()\n",
        "    for i in range(x.shape[1]): \n",
        "      split_imp[i]=0\n",
        "    '''\n",
        "    A node object that is recursivly called within itslef to construct a regression tree. Based on Tianqi Chen's XGBoost \n",
        "    the internal gain used to find the optimal split value uses both the gradient and hessian. Also a weighted quantlie sketch \n",
        "    and optimal leaf values all follow Chen's description in \"XGBoost: A Scalable Tree Boosting System\" the only thing not \n",
        "    implemented in this version is sparsity aware fitting or the ability to handle NA values with a default direction.\n",
        "    Inputs\n",
        "    ------------------------------------------------------------------------------------------------------------------\n",
        "    x: pandas datframe of the training data\n",
        "    gradient: negative gradient of the loss function\n",
        "    hessian: second order derivative of the loss function\n",
        "    idxs: used to keep track of samples within the tree structure\n",
        "    subsample_cols: is an implementation of layerwise column subsample randomizing the structure of the trees\n",
        "    (complexity parameter)\n",
        "    min_leaf: minimum number of samples for a node to be considered a node (complexity parameter)\n",
        "    min_child_weight: sum of the heassian inside a node is a meaure of purity (complexity parameter)\n",
        "    depth: limits the number of layers in the tree\n",
        "    lambda: L2 regularization term on weights. Increasing this value will make model more conservative.\n",
        "    gamma: This parameter also prevents over fitting and is present in the the calculation of the gain (structure score). \n",
        "    As this is subtracted from the gain it essentially sets a minimum gain amount to make a split in a node.\n",
        "    eps: This parameter is used in the quantile weighted skecth or 'approx' tree method roughly translates to \n",
        "    (1 / sketch_eps) number of bins\n",
        "    Outputs\n",
        "    --------------------------------------------------------------------------------------------------------------------\n",
        "    A single tree object that will be used for gradient boosintg.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, x, gradient, hessian, idxs, subsample_cols = 0.8 , min_leaf = 5, min_child_weight = 1 ,depth = 10, lambda_ = 1, gamma = 1, eps = 0.1):\n",
        "      \n",
        "        self.x, self.gradient, self.hessian = x, gradient, hessian\n",
        "        self.idxs = idxs \n",
        "        self.depth = depth\n",
        "        self.min_leaf = min_leaf\n",
        "        self.lambda_ = lambda_\n",
        "        self.gamma  = gamma\n",
        "        self.min_child_weight = min_child_weight\n",
        "        self.row_count = len(idxs)\n",
        "        self.col_count = x.shape[1]\n",
        "        self.subsample_cols = subsample_cols\n",
        "        self.eps = eps\n",
        "        self.column_subsample = np.random.permutation(self.col_count)[:round(self.subsample_cols*self.col_count)]\n",
        "        self.val = self.compute_gamma(self.gradient[self.idxs], self.hessian[self.idxs])\n",
        "        self.score = float('-inf')\n",
        "        self.find_varsplit()\n",
        "        \n",
        "        \n",
        "    def compute_gamma(self, gradient, hessian):\n",
        "        '''\n",
        "        Calculates the optimal leaf value equation (5) in \"XGBoost: A Scalable Tree Boosting System\"\n",
        "        '''\n",
        "        return(-np.sum(gradient)/(np.sum(hessian) + self.lambda_))\n",
        "        \n",
        "    def find_varsplit(self):\n",
        "        '''\n",
        "        Scans through every column and calcuates the best split point.\n",
        "        The node is then split at this point and two new nodes are created.\n",
        "        Depth is only parameter to change as we have added a new layer to tre structure.\n",
        "        If no split is better than the score initalised at the begining then no splits further splits are made\n",
        "        '''\n",
        "        for c in self.column_subsample: \n",
        "          self.find_greedy_split(c) ## features sampled\n",
        "        # print(self.score)     \n",
        "        if self.is_leaf: return\n",
        "        x = self.split_col\n",
        "        lhs = np.nonzero(x <= self.split)[0]\n",
        "        rhs = np.nonzero(x > self.split)[0]\n",
        "        self.lhs = Node(x = self.x, gradient = self.gradient, hessian = self.hessian, idxs = self.idxs[lhs], min_leaf = self.min_leaf, depth = self.depth-1, lambda_ = self.lambda_ , gamma = self.gamma, min_child_weight = self.min_child_weight, eps = self.eps, subsample_cols = self.subsample_cols)\n",
        "        self.rhs = Node(x = self.x, gradient = self.gradient, hessian = self.hessian, idxs = self.idxs[rhs], min_leaf = self.min_leaf, depth = self.depth-1, lambda_ = self.lambda_ , gamma = self.gamma, min_child_weight = self.min_child_weight, eps = self.eps, subsample_cols = self.subsample_cols)\n",
        "    def find_greedy_split(self, var_idx):\n",
        "        '''\n",
        "         For a given feature greedily calculates the gain at each split.\n",
        "         Globally updates the best score and split point if a better split point is found\n",
        "        '''\n",
        "        x = self.x.values[self.idxs, var_idx]\n",
        "        # print('var_idx',var_idx)\n",
        "        for r in range(self.row_count):\n",
        "            lhs = x <= x[r]\n",
        "            rhs = x > x[r]\n",
        "            \n",
        "            lhs_indices = np.nonzero(x <= x[r])[0]\n",
        "            rhs_indices = np.nonzero(x > x[r])[0]\n",
        "            if(rhs.sum() < self.min_leaf or lhs.sum() < self.min_leaf \n",
        "               or self.hessian[lhs_indices].sum() < self.min_child_weight\n",
        "               or self.hessian[rhs_indices].sum() < self.min_child_weight): continue\n",
        "\n",
        "            curr_score = self.gain(lhs, rhs)\n",
        "            if curr_score > self.score: \n",
        "                self.var_idx = var_idx\n",
        "                self.score = curr_score\n",
        "                self.split = x[r]\n",
        "        \n",
        "    def weighted_qauntile_sketch(self, var_idx):\n",
        "        '''\n",
        "        XGBOOST Mini-Version\n",
        "        Yiyang \"Joe\" Zeng\n",
        "        Is an approximation to the eact greedy approach faster for bigger datasets wher it is not feasible\n",
        "        to calculate the gain at every split point. Uses equation (8) and (9) from \"XGBoost: A Scalable Tree Boosting System\"\n",
        "        '''\n",
        "        x = self.x.values[self.idxs, var_idx]\n",
        "        hessian_ = self.hessian[self.idxs]\n",
        "        df = pd.DataFrame({'feature':x,'hess':hessian_})\n",
        "        \n",
        "        df.sort_values(by=['feature'], ascending = True, inplace = True)\n",
        "        hess_sum = df['hess'].sum() \n",
        "        df['rank'] = df.apply(lambda x : (1/hess_sum)*sum(df[df['feature'] < x['feature']]['hess']), axis=1)\n",
        "        \n",
        "        for row in range(df.shape[0]-1):\n",
        "            # look at the current rank and the next ran\n",
        "            rk_sk_j, rk_sk_j_1 = df['rank'].iloc[row:row+2]\n",
        "            diff = abs(rk_sk_j - rk_sk_j_1)\n",
        "            if(diff >= self.eps):\n",
        "                continue\n",
        "                \n",
        "            split_value = (df['rank'].iloc[row+1] + df['rank'].iloc[row])/2\n",
        "            lhs = x <= split_value\n",
        "            rhs = x > split_value\n",
        "            \n",
        "            lhs_indices = np.nonzero(x <= split_value)[0]\n",
        "            rhs_indices = np.nonzero(x > split_value)[0]\n",
        "            if(rhs.sum() < self.min_leaf or lhs.sum() < self.min_leaf \n",
        "               or self.hessian[lhs_indices].sum() < self.min_child_weight\n",
        "               or self.hessian[rhs_indices].sum() < self.min_child_weight): continue\n",
        "                \n",
        "            curr_score = self.gain(lhs, rhs)\n",
        "            if curr_score > self.score: \n",
        "                self.var_idx = var_idx\n",
        "                self.score = curr_score\n",
        "                self.split = split_value\n",
        "                \n",
        "    def gain(self, lhs, rhs):\n",
        "        '''\n",
        "        Calculates the gain at a particular split point bases on equation (7) from\n",
        "        \"XGBoost: A Scalable Tree Boosting System\"\n",
        "        '''\n",
        "        gradient = self.gradient[self.idxs]\n",
        "        hessian  = self.hessian[self.idxs]\n",
        "        \n",
        "        lhs_gradient = gradient[lhs].sum()\n",
        "        lhs_hessian  = hessian[lhs].sum()\n",
        "        \n",
        "        rhs_gradient = gradient[rhs].sum()\n",
        "        rhs_hessian  = hessian[rhs].sum()\n",
        "        \n",
        "        gain = 0.5 *( (lhs_gradient**2/(lhs_hessian + self.lambda_)) + (rhs_gradient**2/(rhs_hessian + self.lambda_)) - ((lhs_gradient + rhs_gradient)**2/(lhs_hessian + rhs_hessian + self.lambda_))) - self.gamma\n",
        "        return(gain)\n",
        "                \n",
        "    @property\n",
        "    def split_col(self):\n",
        "        '''\n",
        "        splits a column \n",
        "        '''\n",
        "        print(self.var_idx)\n",
        "        Node.split_imp[self.var_idx]=Node.split_imp[self.var_idx]+1 ## calculate imp by split\n",
        "        print(Node.split_imp)\n",
        "        return self.x.values[self.idxs , self.var_idx]\n",
        "                \n",
        "    @property\n",
        "    def is_leaf(self):\n",
        "        '''\n",
        "        checks if node is a leaf\n",
        "        '''\n",
        "        return self.score == float('-inf') or self.depth <= 0                 \n",
        "\n",
        "    def predict(self, x):\n",
        "        return np.array([self.predict_row(xi) for xi in x])\n",
        "    \n",
        "    def predict_row(self, xi):\n",
        "        if self.is_leaf:\n",
        "            return(self.val)\n",
        "\n",
        "        node = self.lhs if xi[self.var_idx] <= self.split else self.rhs\n",
        "        return node.predict_row(xi)\n"
      ],
      "id": "c2a49c16",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ced1760"
      },
      "source": [
        "class XGBoostTree:\n",
        "    '''\n",
        "    Wrapper class that provides a scikit learn interface to the recursive regression tree above\n",
        "    \n",
        "    Inputs\n",
        "    ------------------------------------------------------------------------------------------------------------------\n",
        "    x: pandas datframe of the training data\n",
        "    gradient: negative gradient of the loss function\n",
        "    hessian: second order derivative of the loss function\n",
        "    idxs: used to keep track of samples within the tree structure\n",
        "    subsample_cols: is an implementation of layerwise column subsample randomizing the structure of the trees\n",
        "    (complexity parameter)\n",
        "    min_leaf: minimum number of samples for a node to be considered a node (complexity parameter)\n",
        "    min_child_weight: sum of the heassian inside a node is a meaure of purity (complexity parameter)\n",
        "    depth: limits the number of layers in the tree\n",
        "    lambda: L2 regularization term on weights. Increasing this value will make model more conservative.\n",
        "    gamma: This parameter also prevents over fitting and is present in the the calculation of the gain (structure score). \n",
        "    As this is subtracted from the gain it essentially sets a minimum gain amount to make a split in a node.\n",
        "    eps: This parameter is used in the quantile weighted skecth or 'approx' tree method roughly translates to \n",
        "    (1 / sketch_eps) number of bins\n",
        "    \n",
        "    Outputs\n",
        "    --------------------------------------------------------------------------------------------------------------------\n",
        "    A single tree object that will be used for gradient boosintg.\n",
        "    \n",
        "    '''\n",
        "    def fit(self, x, gradient, hessian, subsample_cols = 0.8 , min_leaf = 5, min_child_weight = 1 ,depth = 10, lambda_ = 1, gamma = 1, eps = 0.1):\n",
        "        self.dtree = Node(x, gradient, hessian, np.array(np.arange(len(x))), subsample_cols, min_leaf, min_child_weight, depth, lambda_, gamma, eps)        \n",
        "        return self\n",
        "    def predict(self, X):\n",
        "        return self.dtree.predict(X.values)\n",
        "    # def fe_imp_split(self):\n",
        "    #     return self.dtree.split_imp"
      ],
      "id": "1ced1760",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b21efb1"
      },
      "source": [
        "class XGBoostClassifier:\n",
        "    '''\n",
        "    Full application of the XGBoost algorithm as described in \"XGBoost: A Scalable Tree Boosting System\" for \n",
        "    Binary Classification.\n",
        "    Inputs\n",
        "    ------------------------------------------------------------------------------------------------------------------\n",
        "    x: pandas datframe of the training data\n",
        "    gradient: negative gradient of the loss function\n",
        "    hessian: second order derivative of the loss function\n",
        "    idxs: used to keep track of samples within the tree structure\n",
        "    subsample_cols: is an implementation of layerwise column subsample randomizing the structure of the trees\n",
        "    (complexity parameter)\n",
        "    min_leaf: minimum number of samples for a node to be considered a node (complexity parameter)\n",
        "    min_child_weight: sum of the heassian inside a node is a meaure of purity (complexity parameter)\n",
        "    depth: limits the number of layers in the tree\n",
        "    lambda: L2 regularization term on weights. Increasing this value will make model more conservative.\n",
        "    gamma: This parameter also prevents over fitting and is present in the the calculation of the gain (structure score). \n",
        "    As this is subtracted from the gain it essentially sets a minimum gain amount to make a split in a node.\n",
        "    eps: This parameter is used in the quantile weighted skecth or 'approx' tree method roughly translates to \n",
        "    (1 / sketch_eps) number of bins\n",
        "    Outputs\n",
        "    --------------------------------------------------------------------------------------------------------------------\n",
        "    A single tree object that will be used for gradient boosintg.\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        self.estimators = []\n",
        "    \n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    \n",
        "    # first order gradient logLoss\n",
        "    def grad(self, preds, labels):\n",
        "        preds = self.sigmoid(preds)\n",
        "        return(preds - labels)\n",
        "    \n",
        "    # second order gradient logLoss\n",
        "    def hess(self, preds, labels):\n",
        "        preds = self.sigmoid(preds)\n",
        "        return(preds * (1 - preds))\n",
        "    \n",
        "    @staticmethod\n",
        "    def log_odds(column):\n",
        "        binary_yes = np.count_nonzero(column == 1)\n",
        "        binary_no  = np.count_nonzero(column == 0)\n",
        "        return(np.log(binary_yes/binary_no))\n",
        "    \n",
        "    \n",
        "    def fit(self, X, y, subsample_cols = 0.8 , min_child_weight = 1, depth = 5, min_leaf = 5, learning_rate = 0.4, boosting_rounds = 5, lambda_ = 1.5, gamma = 1, eps = 0.1):\n",
        "        self.X, self.y = X, y.values\n",
        "        self.depth = depth\n",
        "        self.subsample_cols = subsample_cols\n",
        "        self.eps = eps\n",
        "        self.min_child_weight = min_child_weight \n",
        "        self.min_leaf = min_leaf\n",
        "        self.learning_rate = learning_rate\n",
        "        self.boosting_rounds = boosting_rounds \n",
        "        self.lambda_ = lambda_\n",
        "        self.gamma  = gamma\n",
        "        # self.feature_importance_split = {}\n",
        "        self.base_pred = np.full((X.shape[0], 1), 1).flatten().astype('float64')\n",
        "    \n",
        "        for booster in range(self.boosting_rounds):\n",
        "            Grad = self.grad(self.base_pred, self.y)\n",
        "            Hess = self.hess(self.base_pred, self.y)\n",
        "            clf=XGBoostTree()\n",
        "            boosting_tree = clf.fit(self.X, Grad, Hess, depth = self.depth, min_leaf = self.min_leaf, lambda_ = self.lambda_, gamma = self.gamma, eps = self.eps, min_child_weight = self.min_child_weight, subsample_cols = self.subsample_cols)\n",
        "            self.base_pred += self.learning_rate * boosting_tree.predict(self.X)\n",
        "            self.estimators.append(boosting_tree)\n",
        "            # self.feature_importance_split = clf.fe_imp_split() ## feature importance split\n",
        "    def predict_proba(self, X):\n",
        "        pred = np.zeros(X.shape[0])\n",
        "        \n",
        "        for estimator in self.estimators:\n",
        "            pred += self.learning_rate * estimator.predict(X) \n",
        "          \n",
        "        return(self.sigmoid(np.full((X.shape[0], 1), 1).flatten().astype('float64') + pred))\n",
        "    \n",
        "    def predict(self, X):\n",
        "        pred = np.zeros(X.shape[0])\n",
        "        for estimator in self.estimators:\n",
        "            pred += self.learning_rate * estimator.predict(X) \n",
        "        \n",
        "        predicted_probas = self.sigmoid(np.full((X.shape[0], 1), 1).flatten().astype('float64') + pred)\n",
        "        preds = np.where(predicted_probas > np.mean(predicted_probas), 1, 0)\n",
        "        return(preds)\n"
      ],
      "id": "0b21efb1",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF6iEgXhucGj"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns # for correlation heatmap\n",
        "data = load_breast_cancer(as_frame=True)\n",
        "x=data.data\n",
        "y=data.target"
      ],
      "id": "BF6iEgXhucGj",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyOtJcpYvFqU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bdcf4652-29a9-417d-b8a2-3fdca71b1fda"
      },
      "source": [
        "model = XGBoostClassifier()\n",
        "model.fit(x.iloc[0:400,:], y[0:400], min_leaf=5, depth=3)\n",
        "imp_=Node.split_imp # dict track the feature importance\n",
        "plt.barh(data.feature_names, imp_.values()) ## plot feature importance plot (split)"
      ],
      "id": "JyOtJcpYvFqU",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0}\n",
            "20\n",
            "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0}\n",
            "1\n",
            "{0: 0, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 0, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0}\n",
            "21\n",
            "{0: 0, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 1, 22: 0, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0}\n",
            "22\n",
            "{0: 0, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 1, 22: 1, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0}\n",
            "21\n",
            "{0: 0, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 2, 22: 1, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0}\n",
            "21\n",
            "{0: 0, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 3, 22: 1, 23: 0, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0}\n",
            "23\n",
            "{0: 0, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 3, 22: 1, 23: 1, 24: 0, 25: 0, 26: 0, 27: 0, 28: 0, 29: 0}\n",
            "27\n",
            "{0: 0, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 3, 22: 1, 23: 1, 24: 0, 25: 0, 26: 0, 27: 1, 28: 0, 29: 0}\n",
            "12\n",
            "{0: 0, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 3, 22: 1, 23: 1, 24: 0, 25: 0, 26: 0, 27: 1, 28: 0, 29: 0}\n",
            "27\n",
            "{0: 0, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 3, 22: 1, 23: 1, 24: 0, 25: 0, 26: 0, 27: 2, 28: 0, 29: 0}\n",
            "0\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 3, 22: 1, 23: 1, 24: 0, 25: 0, 26: 0, 27: 2, 28: 0, 29: 0}\n",
            "26\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 3, 22: 1, 23: 1, 24: 0, 25: 0, 26: 1, 27: 2, 28: 0, 29: 0}\n",
            "23\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 3, 22: 1, 23: 2, 24: 0, 25: 0, 26: 1, 27: 2, 28: 0, 29: 0}\n",
            "26\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 3, 22: 1, 23: 2, 24: 0, 25: 0, 26: 2, 27: 2, 28: 0, 29: 0}\n",
            "21\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 4, 22: 1, 23: 2, 24: 0, 25: 0, 26: 2, 27: 2, 28: 0, 29: 0}\n",
            "24\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 4, 22: 1, 23: 2, 24: 1, 25: 0, 26: 2, 27: 2, 28: 0, 29: 0}\n",
            "26\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 0, 9: 0, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 4, 22: 1, 23: 2, 24: 1, 25: 0, 26: 3, 27: 2, 28: 0, 29: 0}\n",
            "8\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 4, 22: 1, 23: 2, 24: 1, 25: 0, 26: 3, 27: 2, 28: 0, 29: 0}\n",
            "23\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 4, 22: 1, 23: 3, 24: 1, 25: 0, 26: 3, 27: 2, 28: 0, 29: 0}\n",
            "27\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 1, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 4, 22: 1, 23: 3, 24: 1, 25: 0, 26: 3, 27: 3, 28: 0, 29: 0}\n",
            "12\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 2, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 4, 22: 1, 23: 3, 24: 1, 25: 0, 26: 3, 27: 3, 28: 0, 29: 0}\n",
            "4\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 1, 5: 0, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 2, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 4, 22: 1, 23: 3, 24: 1, 25: 0, 26: 3, 27: 3, 28: 0, 29: 0}\n",
            "26\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 1, 5: 0, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 2, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 4, 22: 1, 23: 3, 24: 1, 25: 0, 26: 4, 27: 3, 28: 0, 29: 0}\n",
            "5\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 1, 5: 1, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 2, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 4, 22: 1, 23: 3, 24: 1, 25: 0, 26: 4, 27: 3, 28: 0, 29: 0}\n",
            "21\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 1, 5: 1, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 2, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 5, 22: 1, 23: 3, 24: 1, 25: 0, 26: 4, 27: 3, 28: 0, 29: 0}\n",
            "22\n",
            "{0: 1, 1: 1, 2: 0, 3: 0, 4: 1, 5: 1, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 2, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 5, 22: 2, 23: 3, 24: 1, 25: 0, 26: 4, 27: 3, 28: 0, 29: 0}\n",
            "1\n",
            "{0: 1, 1: 2, 2: 0, 3: 0, 4: 1, 5: 1, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 2, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 5, 22: 2, 23: 3, 24: 1, 25: 0, 26: 4, 27: 3, 28: 0, 29: 0}\n",
            "28\n",
            "{0: 1, 1: 2, 2: 0, 3: 0, 4: 1, 5: 1, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 2, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 5, 22: 2, 23: 3, 24: 1, 25: 0, 26: 4, 27: 3, 28: 1, 29: 0}\n",
            "27\n",
            "{0: 1, 1: 2, 2: 0, 3: 0, 4: 1, 5: 1, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 2, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 5, 22: 2, 23: 3, 24: 1, 25: 0, 26: 4, 27: 4, 28: 1, 29: 0}\n",
            "29\n",
            "{0: 1, 1: 2, 2: 0, 3: 0, 4: 1, 5: 1, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 2, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 5, 22: 2, 23: 3, 24: 1, 25: 0, 26: 4, 27: 4, 28: 1, 29: 1}\n",
            "15\n",
            "{0: 1, 1: 2, 2: 0, 3: 0, 4: 1, 5: 1, 6: 0, 7: 1, 8: 1, 9: 0, 10: 0, 11: 0, 12: 2, 13: 0, 14: 0, 15: 1, 16: 0, 17: 0, 18: 0, 19: 0, 20: 1, 21: 5, 22: 2, 23: 3, 24: 1, 25: 0, 26: 4, 27: 4, 28: 1, 29: 1}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 30 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2OvHru9BINA"
      },
      "source": [
        ""
      ],
      "id": "B2OvHru9BINA",
      "execution_count": null,
      "outputs": []
    }
  ]
}